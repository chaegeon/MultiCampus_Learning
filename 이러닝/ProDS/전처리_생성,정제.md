# 데이터 전처리

## 데이터 생성, 데이터 정제

- 데이터 마이닝
  - 대용량 데이터로부터 패턴을 파악하고 정보를 만들어 냄
- 머신러닝 알고리즘
  - 데이터의 패턴을 파악하는데 사용되는 알고리즘

```
#요약변수 #파생변수 #이상치 #결측치 #Binning
```

### 데이터 생성

- 요약변수
  - 수집된 정보를 분석의 못적에 맞게 종합한 변수(aggregate)
    - 방식은 누가봐도 똑같은 결과가 나올 수 있는, 객관적인 원리에 의해 종합되어야 함
    - Ex). 단어빈도, 상품별 구매금액, 상품별 구매량, 영화 매출액 등등
  - 재활용성이 높음

- 파생변수

  - 특정한 의미를 갖는 작위적 정의에 의한 변수
  - 사용자가 특정조건을 만족하거나 특정 함수에 의해 값을 만들어 의미를 부여한 변수
  - 매우 주관적일 수 있으므로 논리작 타당성을 갖추어야 함
    - Ex). 구매상품 다양성 변수, 가격 선호대 변수, 라이프 스타일 변수, 영화 인기도 변수
    - 다양하다는 걸 어떻게 정의할 것인가, 어느만큼을 좋아해야 선호하는 것인지, 라이프 스타일을 어떻게 분류할 것인지, 어느수준이어야 인기있는 수준인지 등등


### 데이터 정제

#### 결측값의 이해 ( Missing Value)

- 기록누락, 미응답, 수집오류(오표기) 등의 이유로 결측이 발생
- 결측값이 포함된 자료라도 나머지 변수의 값들은 의미있는 정보이므로, 정보의 손실을 최소하 하도록 결측을 처리하는 것이 바람직
- 가능하면 모든 정보를 반영하도록 하는 것이 바람직함
- 가능한 남아있는 값이라도 잘 살리기 위해 결측치를 적절한 값으로 대체하는 방법들


#### 결측값 처리 방법

- 완전제거법(list-wise deletion)
  - 결측값이 하나 이상 포함된 자료를 제거하는 방법
  - 정보의 손실로 분석결과가 왜곡될 수 있음

- 평균대체법(mean value imputation)

- 적절한 값으로 대체하는 방법 중 가장 단순하면서 가장 많이 활용되는 방법
- 결측값을 해당 변수의 나머지 값들의 평균으로 대체하는 방법
- Ex). `5, NaN, 17` => `5, 11, 17`
- 추정량의 표준오차가 과소추정되는 문제가 있음
  - 5, NaN, 17 만약 실제 결측치의 값이 5와 17사이가 아니라 동떨어진 값일 수도 있음.
    - Ex). 5, 29, 17 이었을 수도..
    - -> 이 자료의 변동성은 원래 5, 17, 29 만큼의 변동성을 가지는 자료였는데 평균으로 대체하면서 자료의 변동성이 작게 측정이 된 것.
    - -> 자료의 변동성이 작다면 추정의 오차가 줄어들게 되는데, 실제 데이터의 변동성은 그렇지 않음 
    - -> 변동성이 작을 것이라고 가정을 하고 '추정이 잘 될 거다', '추정 오차가 줄어들 것이다' 라고 잘못된 판단을 할 수가 있는거임
  - 어떤 추정을 했을 때 그 추정의 오차가 분석에서 제시한 값보다 훨씬 클수가 있다는 것을 염두에 둬야 함